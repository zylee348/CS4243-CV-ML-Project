{"cells":[{"cell_type":"markdown","metadata":{"id":"-3hPYGaXqxpo"},"source":["# CS4243 Computer Vision Project\n"]},{"cell_type":"markdown","metadata":{"id":"JNDQEmMYussh"},"source":[]},{"cell_type":"markdown","metadata":{"id":"wxtguy7Sq3p3"},"source":["## Part 1: Setting up\n"]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-zx4swrqMDT","executionInfo":{"status":"ok","timestamp":1700151691765,"user_tz":-480,"elapsed":365,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}},"outputId":"0fc8191d-9789-4d1c-ac95-70aff2ab56ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-F5H8OzqLDr"},"outputs":[],"source":["# Function estimation using neural network, libraries\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from numpy import asarray\n","from matplotlib import pyplot as plt\n","import math as m\n","import random as r\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19331,"status":"ok","timestamp":1700151727292,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"},"user_tz":-480},"id":"ThLVOQBvqTYN","outputId":"43779f04-60a9-412d-ea1c-660b42b05dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"TxhHyZuvqqMS"},"source":["## Part 2: Train our model\n","We first load data using the `tf.keras.utils.image_dataset_from_directory` utility. We split the images from the train directory into two, to be used for training of the model and validating its performance (note that it is not for testing the final performance of the model).\n","\n","You can view the output from these datasets which we loaded."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pNtcgPoqU3Z"},"outputs":[],"source":["# setting the train and evaluation dataset directories. Change the below to your own path\n","# root_path = '/content/drive/MyDrive/CS4243 Project/data/frames/'\n","train_path = '/content/drive/MyDrive/CS4243 Project/data/image_data_cleaned'\n","test_path = '/content/drive/MyDrive/CS4243 Project/data/test_image_data_cleaned'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18144,"status":"ok","timestamp":1700151745431,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"},"user_tz":-480},"id":"uPPzoUeAqWjI","outputId":"1bba2f6c-c043-40ff-d534-9dde79960593"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3363 files belonging to 2 classes.\n","Found 1931 files belonging to 2 classes.\n"]}],"source":["image_size = (256,256)\n","batch_size = 32\n","\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_path,\n","    seed=110,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_path,\n","    seed=110,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")"]},{"cell_type":"markdown","metadata":{"id":"QN6iyiWhycVK"},"source":["#### Showing the images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dCjyKHEyb33"},"outputs":[],"source":["# showing the images\n","# #\n","# plt.figure(figsize=(10, 10))\n","# for images, labels in train_ds.take(1):\n","#     for i in range(4):\n","#         ax = plt.subplot(2, 2, i + 1)\n","#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n","#         plt.title(int(labels[i]))\n","#         plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"Ap4Q3hIAqZgi"},"source":["### Data augmentation\n","Using horizontal flip, and random rotation rotation factor is between 0 to 0.1*2pi\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9cXnMtdqZDE"},"outputs":[],"source":["# data augmentation, using horizontal flip, and random rotation\n","# rotation factor is between 0 to 0.1*2pi\n","#\n","mean = [0.485, 0.456, 0.406]\n","var = np.power(np.array([0.229, 0.224, 0.225]), 2)\n","\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(0.2),\n","        # layers.experimental.preprocessing.Normalization(mean=mean, variance=var),\n","        layers.experimental.preprocessing.Resizing(height=image_size[0], width=image_size[1]),\n","    ]\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"KceAm4z3yxxF"},"source":["We define our model here which is essentially a Convolutional Neural Network. If you are not familiar with CNNs, I would recommend reading this <a href=\"https://aigents.co/data-science-blog/publication/introduction-to-convolutional-neural-networks-cnns\">article</a> and this fun <a href=\"https://setosa.io/ev/image-kernels/\">playground</a> (full credits to their corresponding authors.)\n","\n","Some key points to help you understand some components below:\n","- Input() is used to instantiate a Keras tensor. It is more of a symbolic use rather than it meaning a mathematical operation - it's a way to define how the input data to the model should look.\n","- Batch normalization normalizes the activations of a layer to have zero mean and unit variance, helping to stabilize and accelerate training by reducing internal covariate shift.\n","- Residual refers to residual connections which allow gradients to \"skip\" layers by adding the original input to the output, helping to mitigate the vanishing gradient problem and enabling deeper networks to be trained more effectively.\n","\n","FYI: Prof Amir uses Separable Convolutions layers here instead of the normal Conv2D layers you might be used to. Just note that this is just a variant of Convolution Layers, and at your own time may read up more about it. One resource is this <a href=\"https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\">link</a>. Understanding this specific layer is not the objective of today's lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRKtRagsyzTH"},"outputs":[],"source":["def make_model(input_shape):\n","    inputs = keras.Input(shape=input_shape)\n","    # Image augmentation block\n","    x = data_augmentation(inputs)\n","\n","    # Entry block\n","    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    previous_block_activation = x  # Set aside residual\n","    for size in [128, 256, 512, 728]:\n","\n","        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","        x = layers.BatchNormalization()(x)\n","        x = layers.Activation(\"relu\")(x)\n","\n","        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","        x = layers.BatchNormalization()(x)\n","        x = layers.Activation(\"relu\")(x)\n","\n","        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","        # Project residual\n","        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n","            previous_block_activation\n","        )\n","        x = layers.add([x, residual])  # Add back residual\n","        previous_block_activation = x  # Set aside next residual\n","\n","    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","    activation = \"sigmoid\"\n","    units = 1\n","\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(25, activation='relu')(x)\n","    outputs = layers.Dense(units, activation=activation)(x)\n","    return keras.Model(inputs, outputs)\n","# from tensorflow import keras\n","# from tensorflow.keras import layers\n","\n","# def make_model(input_shape):\n","#     inputs = keras.Input(shape=input_shape)\n","#     x = data_augmentation(inputs)\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","#     x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.Conv2D(32, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     for size in [64, 128, 256]:\n","#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","#         x = layers.BatchNormalization()(x)\n","#         x = layers.Activation(\"relu\")(x)\n","#         x = layers.Dropout(0.5)(x)\n","#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","#     x = layers.SeparableConv2D(512, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","\n","#     # Add dropout layers\n","#     x = layers.Dropout(0.5)(x)\n","\n","#     x = layers.Dense(128, activation='relu')(x)\n","\n","#     # Add another dropout layer\n","#     x = layers.Dropout(0.5)(x)\n","\n","#     outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","#     return keras.Model(inputs, outputs)\n","\n","# def make_model(input_shape): # JEVNET\n","#     inputs = keras.Input(shape=input_shape)\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","\n","#     # Convolutional Block 1\n","#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     x = layers.BatchNormalization()(x)\n","\n","#     # Convolutional Block 2\n","#     x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     x = layers.BatchNormalization()(x)\n","\n","#     # # Convolutional Block 3\n","#     # x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","#     # x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","#     # x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     # x = layers.BatchNormalization()(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","\n","#     x = layers.Dense(256, activation='relu')(x)\n","#     x = layers.Dropout(0.5)(x)  # Adding dropout for regularization\n","#     x = layers.Dense(128, activation='relu')(x)\n","#     x = layers.Dropout(0.3)(x)  # Adding dropout for regularization\n","\n","#     outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","#     model = keras.Model(inputs, outputs)\n","\n","#     # # Compile the model\n","#     # model.compile(optimizer='adam',\n","#     #               loss='binary_crossentropy',\n","#     #               metrics=['accuracy'])\n","\n","#     return model\n"]},{"cell_type":"markdown","metadata":{"id":"Fql6ZtUYy5mF"},"source":["As we have learnt from week 10 lab session, we define our model, `compile` to configure our ANN's learning process, and use the `fit` method to start the training process of our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpHXiNiMy8fz"},"outputs":[],"source":["model = make_model(input_shape=image_size + (3,) )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uwpt6MnQy9mt"},"outputs":[],"source":["# compiling and training our model\n","\n","epochs = 4\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-3),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":584,"status":"ok","timestamp":1700151747124,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"},"user_tz":-480},"id":"LJ4tJL8gy_Wo","outputId":"812f7240-a52f-47f4-bdba-8641ed793ac2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n","                                                                                                  \n"," sequential (Sequential)     (None, 256, 256, 3)          0         ['input_1[0][0]']             \n","                                                                                                  \n"," rescaling (Rescaling)       (None, 256, 256, 3)          0         ['sequential[0][0]']          \n","                                                                                                  \n"," conv2d (Conv2D)             (None, 128, 128, 32)         896       ['rescaling[0][0]']           \n","                                                                                                  \n"," batch_normalization (Batch  (None, 128, 128, 32)         128       ['conv2d[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation (Activation)     (None, 128, 128, 32)         0         ['batch_normalization[0][0]'] \n","                                                                                                  \n"," conv2d_1 (Conv2D)           (None, 128, 128, 64)         18496     ['activation[0][0]']          \n","                                                                                                  \n"," batch_normalization_1 (Bat  (None, 128, 128, 64)         256       ['conv2d_1[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_1 (Activation)   (None, 128, 128, 64)         0         ['batch_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," separable_conv2d (Separabl  (None, 128, 128, 128)        8896      ['activation_1[0][0]']        \n"," eConv2D)                                                                                         \n","                                                                                                  \n"," batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['separable_conv2d[0][0]']    \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," separable_conv2d_1 (Separa  (None, 128, 128, 128)        17664     ['activation_2[0][0]']        \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['separable_conv2d_1[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," max_pooling2d (MaxPooling2  (None, 64, 64, 128)          0         ['activation_3[0][0]']        \n"," D)                                                                                               \n","                                                                                                  \n"," conv2d_2 (Conv2D)           (None, 64, 64, 128)          8320      ['activation_1[0][0]']        \n","                                                                                                  \n"," add (Add)                   (None, 64, 64, 128)          0         ['max_pooling2d[0][0]',       \n","                                                                     'conv2d_2[0][0]']            \n","                                                                                                  \n"," separable_conv2d_2 (Separa  (None, 64, 64, 256)          34176     ['add[0][0]']                 \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['separable_conv2d_2[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," separable_conv2d_3 (Separa  (None, 64, 64, 256)          68096     ['activation_4[0][0]']        \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['separable_conv2d_3[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," max_pooling2d_1 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_3 (Conv2D)           (None, 32, 32, 256)          33024     ['add[0][0]']                 \n","                                                                                                  \n"," add_1 (Add)                 (None, 32, 32, 256)          0         ['max_pooling2d_1[0][0]',     \n","                                                                     'conv2d_3[0][0]']            \n","                                                                                                  \n"," separable_conv2d_4 (Separa  (None, 32, 32, 512)          133888    ['add_1[0][0]']               \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['separable_conv2d_4[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," separable_conv2d_5 (Separa  (None, 32, 32, 512)          267264    ['activation_6[0][0]']        \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['separable_conv2d_5[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," max_pooling2d_2 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_4 (Conv2D)           (None, 16, 16, 512)          131584    ['add_1[0][0]']               \n","                                                                                                  \n"," add_2 (Add)                 (None, 16, 16, 512)          0         ['max_pooling2d_2[0][0]',     \n","                                                                     'conv2d_4[0][0]']            \n","                                                                                                  \n"," separable_conv2d_6 (Separa  (None, 16, 16, 728)          378072    ['add_2[0][0]']               \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_8 (Bat  (None, 16, 16, 728)          2912      ['separable_conv2d_6[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_8 (Activation)   (None, 16, 16, 728)          0         ['batch_normalization_8[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," separable_conv2d_7 (Separa  (None, 16, 16, 728)          537264    ['activation_8[0][0]']        \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_9 (Bat  (None, 16, 16, 728)          2912      ['separable_conv2d_7[0][0]']  \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," activation_9 (Activation)   (None, 16, 16, 728)          0         ['batch_normalization_9[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," max_pooling2d_3 (MaxPoolin  (None, 8, 8, 728)            0         ['activation_9[0][0]']        \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_5 (Conv2D)           (None, 8, 8, 728)            373464    ['add_2[0][0]']               \n","                                                                                                  \n"," add_3 (Add)                 (None, 8, 8, 728)            0         ['max_pooling2d_3[0][0]',     \n","                                                                     'conv2d_5[0][0]']            \n","                                                                                                  \n"," separable_conv2d_8 (Separa  (None, 8, 8, 1024)           753048    ['add_3[0][0]']               \n"," bleConv2D)                                                                                       \n","                                                                                                  \n"," batch_normalization_10 (Ba  (None, 8, 8, 1024)           4096      ['separable_conv2d_8[0][0]']  \n"," tchNormalization)                                                                                \n","                                                                                                  \n"," activation_10 (Activation)  (None, 8, 8, 1024)           0         ['batch_normalization_10[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," global_average_pooling2d (  (None, 1024)                 0         ['activation_10[0][0]']       \n"," GlobalAveragePooling2D)                                                                          \n","                                                                                                  \n"," dropout (Dropout)           (None, 1024)                 0         ['global_average_pooling2d[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," dense (Dense)               (None, 25)                   25625     ['dropout[0][0]']             \n","                                                                                                  \n"," dense_1 (Dense)             (None, 1)                    26        ['dense[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 2807275 (10.71 MB)\n","Trainable params: 2798539 (10.68 MB)\n","Non-trainable params: 8736 (34.12 KB)\n","__________________________________________________________________________________________________\n"]}],"source":["# This is a handy function in Keras that lets you look at your model which you have just compiled.\n","# Personally, looking at the output shape is particularly useful when you do CV\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"_iG4hKmvzBZ_","outputId":"5f2a95e5-77ed-49a0-b0a6-a351f80fd4e2","executionInfo":{"status":"error","timestamp":1700152032367,"user_tz":-480,"elapsed":285251,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","  9/106 [=>............................] - ETA: 29:15 - loss: 0.7034 - accuracy: 0.6181"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-aa36c604a39f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = model.fit(\n","    train_ds, epochs=epochs, validation_data=val_ds,\n",")"]},{"cell_type":"markdown","metadata":{"id":"L0bzpaAWzDwf"},"source":["#### Accuracy Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bsl-YJbzC20"},"outputs":[],"source":["# Accuracy curve\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gI8NhTzhzGqy"},"source":["Loss Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec6AuUUczHyZ"},"outputs":[],"source":["# Loss curve\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ew44RaiFzKVq"},"source":["#### Testing classifier with images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpkIeyQlzSYn"},"outputs":[],"source":["# need a way to check the images and quantify them"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}