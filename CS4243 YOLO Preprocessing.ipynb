{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torch\n","!pip install -qr https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9Jt7aMc-3IY","executionInfo":{"status":"ok","timestamp":1700234217976,"user_tz":-480,"elapsed":16781,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}},"outputId":"fa2dad08-c016-4edd-a958-947be8d601e1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.4/645.4 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","import math\n","import cv2\n","import torch\n","import numpy as np\n","from pathlib import Path\n","from matplotlib import pyplot as plt"],"metadata":{"id":"xBTiAcod-DL0","executionInfo":{"status":"ok","timestamp":1700234228858,"user_tz":-480,"elapsed":10890,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Ei8ly8cL8p4P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700234246726,"user_tz":-480,"elapsed":17879,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}},"outputId":"04b5ef95-d056-4995-fbda-6d7d99d7d3d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# setting the train and evaluation dataset directories. Change the below to your own path\n","root_path = '/content/drive/MyDrive/CS4243 Project/data/'\n","train_path = '/content/drive/MyDrive/CS4243 Project/data/frames/train'\n","# test_path = '/content/drive/MyDrive/CS4243 Project/data/frames/test'"],"metadata":{"id":"6ZnnKkwN9KeE","executionInfo":{"status":"ok","timestamp":1700234246727,"user_tz":-480,"elapsed":5,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class_labels = [name for name in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, name))]\n","print(class_labels)\n","# Uncomment to clean a specific folder\n","# class_labels = [\"normal\"]\n","\n","clean_train_path = os.path.join(root_path, \"image_data_cleaned\")"],"metadata":{"id":"4MpYSQo29VDn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700234252976,"user_tz":-480,"elapsed":890,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}},"outputId":"529ebc86-1047-4a85-875d-6838eebb7578"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['norm', 'weap']\n"]}]},{"cell_type":"code","source":["model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"],"metadata":{"id":"cD7gbVwt9l2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_image(image, image_name, class_label):\n","    save_path = os.path.join(clean_train_path, class_label, image_name)\n","    cv2.imwrite(save_path, image)\n","\n","# crop by expanding bounding box by 10% of image size\n","crop_expansion_factor = 0.1\n","\n","def detect_and_crop_person(image_names, class_label):\n","    image_paths = [os.path.join(train_path, class_label, name) for name in image_names]\n","    results = model(image_paths)\n","    detections = results.pandas().xyxy\n","    success = 0\n","    for i, df in enumerate(detections):\n","        if \"person\" in df.name.values:\n","            rows = df[df.name == \"person\"]\n","            min_values = rows.min()\n","            max_values = rows.max()\n","            row_ymin = min_values[\"ymin\"]\n","            row_ymax = max_values[\"ymax\"]\n","            row_xmin = min_values[\"xmin\"]\n","            row_xmax = max_values[\"xmax\"]\n","            image = cv2.imread(image_paths[i])\n","            height, width, _ = image.shape\n","            ymin = max(0, int(row_ymin - height * crop_expansion_factor))\n","            ymax = min(height, int(row_ymax + height * crop_expansion_factor))\n","            xmin = max(0, int(row_xmin - width * crop_expansion_factor))\n","            xmax = min(width, int(row_xmax + width * crop_expansion_factor))\n","            cropped = image[ymin:ymax, xmin:xmax]\n","            success += 1\n","            save_image(cropped, image_names[i], class_label)\n","    # Return number of dropped examples\n","    return len(image_names) - success"],"metadata":{"id":"B3oI98TK97D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# larger is faster, but uses more memory\n","batch_size = 128\n","\n","for label in class_labels:\n","    print(\"Cleaning images from\", label)\n","    input_path = os.path.join(train_path, label)\n","    output_path = os.path.join(clean_train_path, label)\n","    Path(output_path).mkdir(parents=True, exist_ok=True)\n","    image_names = [name for name in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, name))]\n","    image_num = len(image_names)\n","    print(\"Found\", image_num, \"images to be processed in\", math.ceil(image_num / batch_size), \"steps\")\n","    image_name_batches = [image_names[i:i+batch_size] for i in range(0, image_num, batch_size)]\n","    total_processed = 0\n","    total_dropped = 0\n","    for i, name_batch in enumerate(image_name_batches):\n","        total_dropped += detect_and_crop_person(name_batch, label)\n","        total_processed += batch_size\n","        print(f\"Step {i} | Processed: {total_processed} | Dropped: {total_dropped}\")"],"metadata":{"id":"pnMZwqwc-8W1"},"execution_count":null,"outputs":[]}]}