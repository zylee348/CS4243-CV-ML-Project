{"cells":[{"cell_type":"markdown","metadata":{"id":"-3hPYGaXqxpo"},"source":["# CS4243 Computer Vision Project\n"]},{"cell_type":"markdown","metadata":{"id":"JNDQEmMYussh"},"source":[]},{"cell_type":"markdown","metadata":{"id":"wxtguy7Sq3p3"},"source":["## Part 1: Setting up\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-F5H8OzqLDr"},"outputs":[],"source":["# Function estimation using neural network, libraries\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from numpy import asarray\n","from matplotlib import pyplot as plt\n","import math as m\n","import random as r\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4240,"status":"ok","timestamp":1700145766445,"user":{"displayName":"Derrick Khoo","userId":"00227897224050948762"},"user_tz":-480},"id":"ThLVOQBvqTYN","outputId":"67a84eee-64da-4c9b-9d8e-8855296c7ed2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# We will do a simple check to see if we have GPU for training. Please use GPU to accelerate your training.\n","\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please install GPU version of TF\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pexNP6LunNfi","executionInfo":{"status":"ok","timestamp":1700146250191,"user_tz":-480,"elapsed":3,"user":{"displayName":"Derrick Khoo","userId":"00227897224050948762"}},"outputId":"43414095-f69f-4c9f-dbe6-d3cf420c4839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Default GPU Device: /device:GPU:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"TxhHyZuvqqMS"},"source":["## Part 2: Train our model\n","We first load data using the `tf.keras.utils.image_dataset_from_directory` utility. We split the images from the train directory into two, to be used for training of the model and validating its performance (note that it is not for testing the final performance of the model).\n","\n","You can view the output from these datasets which we loaded."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pNtcgPoqU3Z"},"outputs":[],"source":["# setting the train and evaluation dataset directories. Change the below to your own path\n","# root_path = '/content/drive/MyDrive/CS4243 Project/data/frames/'\n","train_path = '/content/drive/MyDrive/CS4243 Project/data/image_data_cleaned'\n","test_path = '/content/drive/MyDrive/CS4243 Project/data/test_image_data_cleaned'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3737,"status":"ok","timestamp":1700146321428,"user":{"displayName":"Derrick Khoo","userId":"00227897224050948762"},"user_tz":-480},"id":"uPPzoUeAqWjI","outputId":"5285aa6c-00f6-481d-bf20-504323de823d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3363 files belonging to 2 classes.\n","Found 1931 files belonging to 2 classes.\n"]}],"source":["image_size = (256,256)\n","batch_size = 28\n","\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_path,\n","    seed=110,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_path,\n","    seed=110,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")"]},{"cell_type":"markdown","metadata":{"id":"QN6iyiWhycVK"},"source":["#### Showing the images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dCjyKHEyb33"},"outputs":[],"source":["# showing the images\n","# #\n","# plt.figure(figsize=(10, 10))\n","# for images, labels in train_ds.take(1):\n","#     for i in range(4):\n","#         ax = plt.subplot(2, 2, i + 1)\n","#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n","#         plt.title(int(labels[i]))\n","#         plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"Ap4Q3hIAqZgi"},"source":["### Data augmentation\n","Using horizontal flip, and random rotation rotation factor is between 0 to 0.1*2pi\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9cXnMtdqZDE"},"outputs":[],"source":["# data augmentation, using horizontal flip, and random rotation\n","# rotation factor is between 0 to 0.1*2pi\n","#\n","mean = [0.485, 0.456, 0.406]\n","var = np.power(np.array([0.229, 0.224, 0.225]), 2)\n","# Mean: [117.28406 110.5347  105.32724] Variance: [202655.95 184776.1  171003.25]??\n","\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(0.2),\n","        layers.experimental.preprocessing.Normalization(mean=mean, variance=var),\n","        layers.experimental.preprocessing.Resizing(height=image_size[0], width=image_size[1]),\n","    ]\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"KceAm4z3yxxF"},"source":["We define our model here which is essentially a Convolutional Neural Network. If you are not familiar with CNNs, I would recommend reading this <a href=\"https://aigents.co/data-science-blog/publication/introduction-to-convolutional-neural-networks-cnns\">article</a> and this fun <a href=\"https://setosa.io/ev/image-kernels/\">playground</a> (full credits to their corresponding authors.)\n","\n","Some key points to help you understand some components below:\n","- Input() is used to instantiate a Keras tensor. It is more of a symbolic use rather than it meaning a mathematical operation - it's a way to define how the input data to the model should look.\n","- Batch normalization normalizes the activations of a layer to have zero mean and unit variance, helping to stabilize and accelerate training by reducing internal covariate shift.\n","- Residual refers to residual connections which allow gradients to \"skip\" layers by adding the original input to the output, helping to mitigate the vanishing gradient problem and enabling deeper networks to be trained more effectively.\n","\n","FYI: Prof Amir uses Separable Convolutions layers here instead of the normal Conv2D layers you might be used to. Just note that this is just a variant of Convolution Layers, and at your own time may read up more about it. One resource is this <a href=\"https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\">link</a>. Understanding this specific layer is not the objective of today's lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRKtRagsyzTH"},"outputs":[],"source":["# def make_model(input_shape):\n","#     inputs = keras.Input(shape=input_shape)\n","#     # Image augmentation block\n","#     x = data_augmentation(inputs)\n","\n","#     # Entry block\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","#     x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.Conv2D(64, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     previous_block_activation = x  # Set aside residual\n","#     for size in [128, 256, 512, 728]:\n","\n","#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","#         x = layers.BatchNormalization()(x)\n","#         x = layers.Activation(\"relu\")(x)\n","\n","#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","#         x = layers.BatchNormalization()(x)\n","#         x = layers.Activation(\"relu\")(x)\n","\n","#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","#         # Project residual\n","#         residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n","#             previous_block_activation\n","#         )\n","#         x = layers.add([x, residual])  # Add back residual\n","#         previous_block_activation = x  # Set aside next residual\n","\n","#     x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","#     activation = \"sigmoid\"\n","#     units = 1\n","\n","#     x = layers.Dropout(0.5)(x)\n","#     x = layers.Dense(25, activation='relu')(x)\n","#     outputs = layers.Dense(units, activation=activation)(x)\n","#     return keras.Model(inputs, outputs)\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def make_model(input_shape):\n","    inputs = keras.Input(shape=input_shape)\n","    x = data_augmentation(inputs)\n","    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","    x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    # x = layers.Conv2D(32, 3, padding=\"same\")(x)\n","    # x = layers.BatchNormalization()(x)\n","    # x = layers.Activation(\"relu\")(x)\n","\n","    # for size in [64, 128, 256]:\n","    #     x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","    #     x = layers.BatchNormalization()(x)\n","    #     x = layers.Activation(\"relu\")(x)\n","    #     x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","    # x = layers.SeparableConv2D(512, 3, padding=\"same\")(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","\n","    # Add dropout layers\n","    x = layers.Dropout(0.5)(x)\n","\n","    x = layers.Dense(128, activation='relu')(x)\n","\n","    # Add another dropout layer\n","    x = layers.Dropout(0.5)(x)\n","\n","    outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","    return keras.Model(inputs, outputs)\n","\n","# def make_model(input_shape): # JEVNET\n","#     inputs = keras.Input(shape=input_shape)\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","\n","#     # Convolutional Block 1\n","#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     x = layers.BatchNormalization()(x)\n","\n","#     # Convolutional Block 2\n","#     x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     x = layers.BatchNormalization()(x)\n","\n","#     # # Convolutional Block 3\n","#     # x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","#     # x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","#     # x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     # x = layers.BatchNormalization()(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","\n","#     x = layers.Dense(256, activation='relu')(x)\n","#     x = layers.Dropout(0.5)(x)  # Adding dropout for regularization\n","#     x = layers.Dense(128, activation='relu')(x)\n","#     x = layers.Dropout(0.3)(x)  # Adding dropout for regularization\n","\n","#     outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","#     model = keras.Model(inputs, outputs)\n","\n","#     # # Compile the model\n","#     # model.compile(optimizer='adam',\n","#     #               loss='binary_crossentropy',\n","#     #               metrics=['accuracy'])\n","\n","#     return model\n"]},{"cell_type":"markdown","metadata":{"id":"Fql6ZtUYy5mF"},"source":["As we have learnt from week 10 lab session, we define our model, `compile` to configure our ANN's learning process, and use the `fit` method to start the training process of our model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpHXiNiMy8fz"},"outputs":[],"source":["model = make_model(input_shape=image_size + (3,) )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uwpt6MnQy9mt"},"outputs":[],"source":["# compiling and training our model\n","\n","epochs = 20\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-3),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1700146345044,"user":{"displayName":"Derrick Khoo","userId":"00227897224050948762"},"user_tz":-480},"id":"LJ4tJL8gy_Wo","outputId":"0cac25a9-27c3-455e-aecc-5e6b7188e8a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," sequential_1 (Sequential)   (None, 256, 256, 3)       0         \n","                                                                 \n"," rescaling_1 (Rescaling)     (None, 256, 256, 3)       0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 128, 128, 16)      448       \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 128, 128, 16)      64        \n"," chNormalization)                                                \n","                                                                 \n"," activation_2 (Activation)   (None, 128, 128, 16)      0         \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 128, 128, 16)      64        \n"," chNormalization)                                                \n","                                                                 \n"," activation_3 (Activation)   (None, 128, 128, 16)      0         \n","                                                                 \n"," global_average_pooling2d_1  (None, 16)                0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               2176      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 2881 (11.25 KB)\n","Trainable params: 2817 (11.00 KB)\n","Non-trainable params: 64 (256.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# This is a handy function in Keras that lets you look at your model which you have just compiled.\n","# Personally, looking at the output shape is particularly useful when you do CV\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_iG4hKmvzBZ_","outputId":"a6fd0c41-c1e3-429e-d999-3bc443c94461"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","121/121 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.6004"]}],"source":["history = model.fit(\n","    train_ds, epochs=epochs, validation_data=val_ds,\n",")"]},{"cell_type":"markdown","metadata":{"id":"L0bzpaAWzDwf"},"source":["#### Accuracy Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bsl-YJbzC20"},"outputs":[],"source":["# Accuracy curve\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gI8NhTzhzGqy"},"source":["Loss Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec6AuUUczHyZ"},"outputs":[],"source":["# Loss curve\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ew44RaiFzKVq"},"source":["#### Testing classifier with images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpkIeyQlzSYn"},"outputs":[],"source":["# need a way to check the images and quantify them"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}