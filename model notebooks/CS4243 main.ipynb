{"cells":[{"cell_type":"markdown","metadata":{"id":"-3hPYGaXqxpo"},"source":["# CS4243 Computer Vision Project\n"]},{"cell_type":"markdown","metadata":{"id":"JNDQEmMYussh"},"source":[]},{"cell_type":"markdown","metadata":{"id":"wxtguy7Sq3p3"},"source":["## Part 1: Setting up\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"f-F5H8OzqLDr","executionInfo":{"status":"ok","timestamp":1700240410590,"user_tz":-480,"elapsed":555,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# Function estimation using neural network, libraries\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import models  # Add this import\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from numpy import asarray\n","from matplotlib import pyplot as plt\n","import math as m\n","import random as r\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2688,"status":"ok","timestamp":1700240413756,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"},"user_tz":-480},"id":"ThLVOQBvqTYN","outputId":"1ee11b2f-28dd-42e9-c963-c542a405391a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# We will do a simple check to see if we have GPU for training. Please use GPU to accelerate your training.\n","\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please install GPU version of TF\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pexNP6LunNfi","executionInfo":{"status":"ok","timestamp":1700240413756,"user_tz":-480,"elapsed":5,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}},"outputId":"0c31ee8f-14ce-42b0-ee29-bf01d57ebb5d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Default GPU Device: /device:GPU:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"TxhHyZuvqqMS"},"source":["## Part 2: Train our model\n","We first load data using the `tf.keras.utils.image_dataset_from_directory` utility. We split the images from the train directory into two, to be used for training of the model and validating its performance (note that it is not for testing the final performance of the model).\n","\n","You can view the output from these datasets which we loaded."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"5pNtcgPoqU3Z","executionInfo":{"status":"ok","timestamp":1700240413756,"user_tz":-480,"elapsed":3,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# setting the train and evaluation dataset directories. Change the below to your own path\n","# root_path = '/content/drive/MyDrive/CS4243 Project/data/frames/'\n","train_path = '/content/drive/MyDrive/CS4243 Project/data/image_data_cleaned'\n","test_path = '/content/drive/MyDrive/CS4243 Project/data/test_image_data_cleaned'\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2081,"status":"ok","timestamp":1700240415834,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"},"user_tz":-480},"id":"uPPzoUeAqWjI","outputId":"e571a7ce-5532-4c0d-b4b5-faeb7df77940"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3363 files belonging to 2 classes.\n","Found 1931 files belonging to 2 classes.\n"]}],"source":["image_size = (256,256)\n","batch_size = 28\n","\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_path,\n","    seed=110,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_path,\n","    seed=110,\n","    image_size=image_size,\n","    batch_size=batch_size,\n",")"]},{"cell_type":"markdown","metadata":{"id":"QN6iyiWhycVK"},"source":["#### Showing the images"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"8dCjyKHEyb33","executionInfo":{"status":"ok","timestamp":1700240415834,"user_tz":-480,"elapsed":20,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# showing the images\n","# #\n","# plt.figure(figsize=(10, 10))\n","# for images, labels in train_ds.take(1):\n","#     for i in range(4):\n","#         ax = plt.subplot(2, 2, i + 1)\n","#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n","#         plt.title(int(labels[i]))\n","#         plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"Ap4Q3hIAqZgi"},"source":["### Data augmentation\n","Using horizontal flip, and random rotation rotation factor is between 0 to 0.1*2pi\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"y9cXnMtdqZDE","executionInfo":{"status":"ok","timestamp":1700240415834,"user_tz":-480,"elapsed":20,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# data augmentation, using horizontal flip, and random rotation\n","# rotation factor is between 0 to 0.1*2pi\n","#\n","mean = [0.485, 0.456, 0.406]\n","var = np.power(np.array([0.229, 0.224, 0.225]), 2)\n","# Mean: [117.28406 110.5347  105.32724] Variance: [202655.95 184776.1  171003.25]??\n","\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(0.2),\n","        layers.experimental.preprocessing.Normalization(mean=mean, variance=var),\n","        layers.experimental.preprocessing.Resizing(height=image_size[0], width=image_size[1]),\n","    ]\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"KceAm4z3yxxF"},"source":["We define our model here which is essentially a Convolutional Neural Network. If you are not familiar with CNNs, I would recommend reading this <a href=\"https://aigents.co/data-science-blog/publication/introduction-to-convolutional-neural-networks-cnns\">article</a> and this fun <a href=\"https://setosa.io/ev/image-kernels/\">playground</a> (full credits to their corresponding authors.)\n","\n","Some key points to help you understand some components below:\n","- Input() is used to instantiate a Keras tensor. It is more of a symbolic use rather than it meaning a mathematical operation - it's a way to define how the input data to the model should look.\n","- Batch normalization normalizes the activations of a layer to have zero mean and unit variance, helping to stabilize and accelerate training by reducing internal covariate shift.\n","- Residual refers to residual connections which allow gradients to \"skip\" layers by adding the original input to the output, helping to mitigate the vanishing gradient problem and enabling deeper networks to be trained more effectively.\n","\n","FYI: Prof Amir uses Separable Convolutions layers here instead of the normal Conv2D layers you might be used to. Just note that this is just a variant of Convolution Layers, and at your own time may read up more about it. One resource is this <a href=\"https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\">link</a>. Understanding this specific layer is not the objective of today's lab."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"SRKtRagsyzTH","executionInfo":{"status":"ok","timestamp":1700240415834,"user_tz":-480,"elapsed":19,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# def make_model(input_shape):\n","#     inputs = keras.Input(shape=input_shape)\n","#     # Image augmentation block\n","#     x = data_augmentation(inputs)\n","\n","#     # Entry block\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","#     x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.Conv2D(64, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     previous_block_activation = x  # Set aside residual\n","#     for size in [128, 256, 512, 728]:\n","\n","#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","#         x = layers.BatchNormalization()(x)\n","#         x = layers.Activation(\"relu\")(x)\n","\n","#         x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","#         x = layers.BatchNormalization()(x)\n","#         x = layers.Activation(\"relu\")(x)\n","\n","#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","#         # Project residual\n","#         residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n","#             previous_block_activation\n","#         )\n","#         x = layers.add([x, residual])  # Add back residual\n","#         previous_block_activation = x  # Set aside next residual\n","\n","#     x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","#     activation = \"sigmoid\"\n","#     units = 1\n","\n","#     x = layers.Dropout(0.5)(x)\n","#     x = layers.Dense(25, activation='relu')(x)\n","#     outputs = layers.Dense(units, activation=activation)(x)\n","#     return keras.Model(inputs, outputs)\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# def make_model(input_shape):\n","#     inputs = keras.Input(shape=input_shape)\n","#     x = data_augmentation(inputs)\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n","#     x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     # x = layers.Conv2D(32, 3, padding=\"same\")(x)\n","#     # x = layers.BatchNormalization()(x)\n","#     # x = layers.Activation(\"relu\")(x)\n","\n","#     # for size in [64, 128, 256]:\n","#     #     x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n","#     #     x = layers.BatchNormalization()(x)\n","#     #     x = layers.Activation(\"relu\")(x)\n","#     #     x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","#     # x = layers.SeparableConv2D(512, 3, padding=\"same\")(x)\n","#     x = layers.BatchNormalization()(x)\n","#     x = layers.Activation(\"relu\")(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","\n","#     # Add dropout layers\n","#     x = layers.Dropout(0.5)(x)\n","\n","#     x = layers.Dense(128, activation='relu')(x)\n","\n","#     # Add another dropout layer\n","#     x = layers.Dropout(0.5)(x)\n","\n","#     outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","#     return keras.Model(inputs, outputs)\n","\n","# def make_model(input_shape): # JEVNET\n","#     inputs = keras.Input(shape=input_shape)\n","#     x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","\n","#     # Convolutional Block 1\n","#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     x = layers.BatchNormalization()(x)\n","\n","#     # Convolutional Block 2\n","#     x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n","#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     x = layers.BatchNormalization()(x)\n","\n","#     # # Convolutional Block 3\n","#     # x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","#     # x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n","#     # x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","#     # x = layers.BatchNormalization()(x)\n","\n","#     x = layers.GlobalAveragePooling2D()(x)\n","\n","#     x = layers.Dense(256, activation='relu')(x)\n","#     x = layers.Dropout(0.5)(x)  # Adding dropout for regularization\n","#     x = layers.Dense(128, activation='relu')(x)\n","#     x = layers.Dropout(0.3)(x)  # Adding dropout for regularization\n","\n","#     outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","#     model = keras.Model(inputs, outputs)\n","\n","#     # # Compile the model\n","#     # model.compile(optimizer='adam',\n","#     #               loss='binary_crossentropy',\n","#     #               metrics=['accuracy'])\n","\n","#     return model\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import models  # Add this import\n","\n","def make_model(input_shape):\n","    # Load the pre-trained VGG16 model (excluding the top dense layers)\n","    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","    # Freeze the pre-trained layers\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    # Create a new model on top of the pre-trained base\n","    model = models.Sequential()\n","    model.add(base_model)\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"Fql6ZtUYy5mF"},"source":["As we have learnt from week 10 lab session, we define our model, `compile` to configure our ANN's learning process, and use the `fit` method to start the training process of our model."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"rpHXiNiMy8fz","executionInfo":{"status":"ok","timestamp":1700240415834,"user_tz":-480,"elapsed":18,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["model = make_model(input_shape=image_size + (3,) )"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Uwpt6MnQy9mt","executionInfo":{"status":"ok","timestamp":1700240429711,"user_tz":-480,"elapsed":2,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# compiling and training our model\n","\n","epochs = 20\n","model.compile(\n","    optimizer='adam',\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1700240430415,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"},"user_tz":-480},"id":"LJ4tJL8gy_Wo","outputId":"3e18bbe5-cbfa-4663-8e20-b3cfc57736c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n","                                                                 \n","=================================================================\n","Total params: 14714688 (56.13 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}],"source":["# This is a handy function in Keras that lets you look at your model which you have just compiled.\n","# Personally, looking at the output shape is particularly useful when you do CV\n","\n","model.summary()"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_iG4hKmvzBZ_","outputId":"d4ef3eaf-ae21-4357-fd9e-fc4c25f1887d","executionInfo":{"status":"error","timestamp":1700240484890,"user_tz":-480,"elapsed":54479,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-aa36c604a39f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Equal defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-34-aa36c604a39f>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1131, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1225, in compute_metrics\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 723, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 969, in sparse_categorical_matches\n\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_3981]"]}],"source":["history = model.fit(\n","    train_ds, epochs=epochs, validation_data=val_ds,\n",")"]},{"cell_type":"markdown","metadata":{"id":"L0bzpaAWzDwf"},"source":["#### Accuracy Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bsl-YJbzC20","executionInfo":{"status":"aborted","timestamp":1700240484891,"user_tz":-480,"elapsed":2,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# Accuracy curve\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gI8NhTzhzGqy"},"source":["Loss Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec6AuUUczHyZ","executionInfo":{"status":"aborted","timestamp":1700240484891,"user_tz":-480,"elapsed":2,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# Loss curve\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ew44RaiFzKVq"},"source":["#### Testing classifier with images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpkIeyQlzSYn","executionInfo":{"status":"aborted","timestamp":1700240484891,"user_tz":-480,"elapsed":2,"user":{"displayName":"ZY Lee","userId":"08371708391741693118"}}},"outputs":[],"source":["# need a way to check the images and quantify them"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}